{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project: Linear Regression\n",
    "\n",
    "- We want to present the relationship between (two) variables linearly\n",
    "\n",
    "- For example, recall the running distance and drinking water \n",
    "\n",
    "- We are interested to obtain the best line describing by `y_pred[i] = w_1 x[i] +w_0` that maps running distance to drinking water\n",
    "\n",
    "- Below, list `x` represents running distance in miles and list `y` represents the drinking water in litres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Water Drinks (Litre)')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAaoUlEQVR4nO3dfZRddX3v8feHMMKpQKYlo5IJIfZqh4LBDJ3LRWkt8tBBipBSeqvLJ3pVWksvSHF6CasX0XstumKxIFRggS0o9QHMimDBGBVFRYE8JxAjVh7MJDbhYULQuTGJ3/vH3oMnJ2fm7Elmn33O2Z/XWmfNnt/Z++zvHMj5nv17+G5FBGZmVl4HFB2AmZkVy4nAzKzknAjMzErOicDMrOScCMzMSu7AogOYrBkzZsScOXOKDsPMrK0sX7786Yjoqfdc2yWCOXPmsGzZsqLDMDNrK5KeHO85dw2ZmZWcE4GZWck5EZiZlVxuiUDSwZIekrRa0iOSPlRnn/MlbZW0Kn28J694zMysvjwHi3cAp0TEC5K6gO9KujciflCz3xci4m9yjMPMzCaQWyKIpJrdC+mvXenDFe7MzFpMrtNHJU0DlgOvAq6PiAfr7Pankt4A/Ai4JCJ+Wud1LgAuAJg9e3aOEZuZtZbFK4dZuGQDm0ZGmdldYWiwj/n9vVN6jlwHiyNid0TMA2YBJ0h6Tc0udwNzIuI4YClw6zivc1NEDETEQE9P3fUQZmYdZ/HKYRYsWsvwyCgBDI+MsmDRWhavHJ7S8zRl1lBEjAD3AWfUtD8TETvSX28Gfq8Z8ZiZtYOFSzYwunP3Hm2jO3ezcMmGKT1PnrOGeiR1p9sV4HTghzX7HFH169nA+rziMTNrN5tGRifVvq/yHCM4Arg1HSc4APhiRHxF0oeBZRFxF3CRpLOBXcCzwPk5xmNm1lZmdlcYrvOhP7O7MqXnyXPW0Bqgv077FVXbC4AFecVgZtbOhgb7WLBo7R7dQ5WuaQwN9k3pedqu6JyZWVmMzQ7Ke9aQE4GZWQub39875R/8tVxryMys5HxFYGZWoxmLuFqJE4GZWZWxRVxjA7Rji7iAjk0G7hoyM6vSrEVcrcSJwMysSrMWcbUSJwIzsyrjLdaa6kVcrcSJwMysytBgH5WuaXu05bGIq5V4sNjMrEqzFnG1EicCM7MazVjE1UrcNWRmVnJOBGZmJedEYGZWck4EZmYl50RgZlZyTgRmZiXnRGBmVnJeR2DWBGUra2ztxYnALGdlLGts7cVdQ2Y5K2NZY2svTgRmOStjWWNrL04EZjkrY1ljay9OBGY5K2NZY2svHiw2y1kZyxpbe3EiMGuCspU1tvbiriEzs5JzIjAzKzknAjOzknMiMDMrOScCM7OScyIwMys5JwIzs5JzIjAzKzknAjOzksstEUg6WNJDklZLekTSh+rsc5CkL0j6saQHJc3JKx4zM6svzyuCHcApEfFaYB5whqQTa/Z5N/BcRLwK+ATwsRzjMTOzOnJLBJF4If21K31EzW7nALem23cCp0pSXjGZmdnech0jkDRN0ipgC7A0Ih6s2aUX+ClAROwCtgGH13mdCyQtk7Rs69ateYZsZlY6uSaCiNgdEfOAWcAJkl6zj69zU0QMRMRAT0/P1AZpZlZyTSlDHREjku4DzgDWVT01DBwJbJR0IDAdeKYZMZlZ51m8ctj3fdgHec4a6pHUnW5XgNOBH9bsdhfwrnT7POCbEVE7jmBm1tDilcMsWLSW4ZFRAhgeGWXBorUsXjlcdGgtL8+uoSOA+yStAR4mGSP4iqQPSzo73ecW4HBJPwb+Frgsx3jMrIMtXLKB0Z2792gb3bmbhUs2FBRR+8itaygi1gD9ddqvqNr+f8Cf5RWDme27dutm2TQyOql2+zWvLDazvbRjN8vM7sqk2u3XnAjMbC/t2M0yNNhHpWvaHm2VrmkMDfYVFFH78M3rzWwv7djNMtZt1U7dWa3CicDM9jKzu8JwnQ/9Vu9mmd/f6w/+fdCwa0jS6yRdL2mNpK2SnpJ0j6QLJU1vRpBm1lzuZimXCa8IJN0LbAK+DHyEpFTEwcDvAG8Evizp6oi4K+9Azax53M1SLppo/ZakGRHx9IQvkGGfqTQwMBDLli1r1unMmq7dpm1ae5C0PCIG6j03YddQ9Qe8pKMknZZuVyQdWruPme2fdpy2ae0v0/RRSe8lKRN9Y9o0C1icV1BmZdWO0zat/WVdR3AhcBLwPEBEPAa8LK+gzMqqHadtWvvLmgh2RMQvx35JK4W6OJzZFPPqWCtC1kTwbUmXAxVJpwN3AHfnF5ZZOXnaphUh64Kyy0juL7wW+EvgHuDmvIKy1uEZLM3laZtWhAmnj0Jyu0ngtoh4W3NCmpinjzbP2AyW6sHLStc0rjp3rj+YzNrMPk8fheR2k8BRkl4y5ZFZS/MMFrNyyNo19BPge5LuAn4+1hgRV+cSlbUEz2AxK4esieA/0scBwKFpm2cNdbh2LTxmZpOTNRE8GhF3VDdI8p3FOtzQYF/dMQLPYDHrLFmnjy7I2GYdZH5/L1edO5fe7goCersrHig260CNqo++CTgT6JV0bdVThwG78gzMWoPru5t1vkZdQ5uAZcDZwPKq9u3AJXkFZWZmzTNhIoiI1cBqSbdHhK8AzMw6UKOuoS9GxH8HVkraa5ZQRByXW2RmZtYUjbqGLk5/npV3IGZmVoxGXUOb059P1j4n6XskpanNzKyNZZ0+Ws/sKYvCzMwKk3VBWT1eWWwdzZVXrSwaDRafO95TgOsMWMeqrbw6du9gwMnAOk6jK4I3T/DcV6YyELNWMlHlVScC6zSNBov/olmBmLUSV161MplwsFjS2yWNu4+k/yLp96c+LLNi+d7BViaNuoYOJ1lMtpykxMRW4GDgVcAfAk+T3MbSrKO48qqVSaOuoWskXQecQrJm4DhgFFgPvCMinso/RLPm66R7B3v2kzXS8J7Frcb3LDbLzvedtjH7dc/i/TjpkZLuk/SopEckXVxnn5MlbZO0Kn1ckVc8ZmXk+05bFvuzoKyRXcClEbFC0qHAcklLI+LRmv2+ExGuZWSWA89+sixyuyKIiM0RsSLd3k4yruBrUbMm8uwnyyJTIpB0saTDlLhF0gpJf5T1JJLmAP3Ag3Wefp2k1ZLulXTsOMdfIGmZpGVbt27Nelqz0hsa7KPSNW2PNs9+slpZrwj+R0Q8D/wR8JvAO4CPZjlQ0iHAl4D3p69RbQVwVES8FvgksLjea0TETRExEBEDPT09GUM2M9932rLIOkag9OeZwGci4hFJmugAAEldJEng9ohYVPt8dWKIiHsk/bOkGRHxdMa4zKwB33faGsl6RbBc0tdIEsGSdPD3VxMdkCaKW4D1EXH1OPu8YiyhSDohjeeZrMGbmdn+y3pF8G5gHvCTiPiFpMOBRnWITiLpQloraVXadjnpfQwi4gbgPOB9knaRLFR7S7TbwgZrOV5AZTY5WRPBlRFRPcd/BLgWeNt4B0TEd/l1l9J4+1wHXJcxBrOGXD7abPKydg0dKWkBgKSDgEXAY7lFZbaPvIDKbPIyzxoC5qbJ4G7gWxFxZW5Rme0jL6Aym7xGZaiPl3Q8yRqAa4A/J7kS+HbabtZSvIDKbPIajRH8Y83vzwHHpO1BUpXUrGW4fLTZ5DUqQ/3GZgViNhU6qXy0WbNkmjWUDhD/KTCn+piI+HA+YZntOy+gMpucrNNHvwxsI7lL2Y78wjEzs2bLmghmRcQZuUZiZmaFyDp99AFJc3ONxMzMCpH1iuD3gfMlPU7SNSQgIuK43CIzM7OmyJoI3pRrFGZmVpgJE4Gkw9JS0dubFI+ZmTVZoyuCfwPOIpktFOxZRC6A384pLjMza5JGC8rOSu8X8IcR8VSTYjIzsyZqOGsovT/AvzchFjMzK0DW6aMrJP3XXCMxM7NCZJ019N+At0t6Avg5nj5qZtYxsiaCwVyjMDOzwmRNBIcBR6fb6yNiXU7xmJlZkzVaRzCdpODckcAaki6huZKeAs5J1xiYmVkbazRY/H+AZcCrI+JPImI+8GrgYeAjeQdnZmb5a9Q1dBpwXET8aqwhIn4l6XJgba6RmZlZUzS6IvhlROyqbUzbfF8CM7MO0OiK4GBJ/exZWoL094PyCcnMzJqpUSLYDFw9znM/m+JYzMysAL55vZlZyWUtMWFmZh0q64Iys5azeOUwC5dsYNPIKDO7KwwN9jG/v7fosMzaTsNEkJahnhURP21CPGaZLF45zIJFaxnduRuA4ZFRFixKZjQ7GZhNTtYy1Pc0IRazzBYu2fBiEhgzunM3C5dsKCgis/blMtTWljaNjE6q3czGN5ky1G+T9CQuQ20tYGZ3heE6H/ozuysFRGPW3lyG2trS0GDfHmMEAJWuaQwN9hUYlVl7ytQ1FBFPklQgPSXd/kXWY83yML+/l6vOnUtvdwUBvd0Vrjp3rgeKzfZBpisCSR8EBoA+4F+ALuCzwEn5hWY2sfn9vf7gN5sCWb/V/wlwNsn4ABGxCTh0ogMkHSnpPkmPSnpE0sV19pGkayX9WNIaScdP9g8wM7P9k3WM4JcREZICQNJLMxyzC7g0IlZIOhRYLmlpRDxatc+bSO5v8GqSAelPpT/NzKxJsl4RfFHSjUC3pPcCXwdunuiAiNgcESvS7e3AeqD2Ov4c4LZI/CB9/SMm9ReYmdl+yXRFEBEfl3Q68DzJOMEVEbE060kkzQH6gQdrnuoFqlcsb0zbNtccfwFwAcDs2bOzntbMzDLIdEUg6WMRsTQihiLiAxGxVNLHMh57CPAl4P37eo/jiLgpIgYiYqCnp2dfXsLMzMaRtWvo9Dptb2p0kKQukiRwe0QsqrPLMMm01DGz0jYzM2uSCROBpPdJWgv0pbN6xh6PA2saHCvgFmB9RIx3c5u7gHems4dOBLZFxOZx9jUzsxw0GiP4N+Be4Crgsqr27RHxbINjTwLeAayVtCptuxyYDRARN5AUszsT+DHJIrW/mFT0Zma23xrdoWwbsA14K4CklwEHA4dIOiQinprg2O+y972Oa/cJ4MLJBm1mZlMn62DxmyU9BjwOfBt4guRKwczM2lzWweL/C5wI/CgiXgmcCvwgt6jMzKxpsiaCnRHxDHCApAMi4j6S2kNmZtbmspaYGEnXA9wP3C5pC2ndITMza29ZrwjOAUaBS4CvAv8BvDmvoMzMrHkmvCKQ9H7gAWBFRIzdAeTW3KMyM7OmadQ1NAv4J+DodGHZ90gSwwMZ1hGYmVkbaLSO4AMAkl5CMjj8epJFXzdJGomIY/IP0czM8pR1sLgCHAZMTx+bgLV5BWVmZs3TaIzgJuBYYDtJCekHgKsj4rkmxGZmZk3QaNbQbOAg4GckVUE3AiN5B2VmZs3TaIzgjLSK6LEk4wOXAq+R9Czw/Yj4YBNiNDOzHDUcI0gLw62TNEJSgG4bcBZwAuBEYGbW5hqNEVxEciXwemAn6dRR4NN4sNjMrCM0uiKYA9wBXOIbxpiZdaZGYwR/26xAzMysGFlrDZmZWYfKuqDMcrZ45TALl2xg08goM7srDA32Mb+/t+iwzKwEnAhawOKVwyxYtJbRnUldv+GRURYsSsbinQw6n78EWNHcNdQCFi7Z8GISGDO6czcLl2woKCJrlrEvAcMjowS//hKweOVw0aFZiTgRtIBNI6OTarfO4S8B1grcNdQCZnZXGK7zoT+zu1JANK2nk7tO/CXAWoGvCFrA0GAfla5pe7RVuqYxNNhXUESto9O7TsZL9v4SYM3kRNAC5vf3ctW5c+ntriCgt7vCVefO7Zhvvfuj07tO/CXAWoG7hlrE/P5ef/DX0eldJ2P/zTu168vagxOBtbQyjJ/4S4AVzV1D1tLcdWKWP18RWEtz14lZ/pwISq4dpma668QsX04EJebSFmYGHiMotU6fmmlm2TgRlFinT800s2ycCErMq1rNDJwISs1TM80MckwEkj4taYukdeM8f7KkbZJWpY8r8orF6nNpCzODfGcN/StwHXDbBPt8JyLOyjEGa8BTM80styuCiLgfeDav1zczs6lR9BjB6yStlnSvpGPH20nSBZKWSVq2devWZsZnZtbxikwEK4CjIuK1wCeBxePtGBE3RcRARAz09PQ0LUAzszIoLBFExPMR8UK6fQ/QJWlGUfGYmZVVYYlA0iskKd0+IY3lmaLiMTMrq9xmDUn6HHAyMEPSRuCDQBdARNwAnAe8T9IuYBR4S0REXvGYmVl9uSWCiHhrg+evI5leamZmBSp61pCZmRXMicDMrOScCMzMSs6JwMys5JwIzMxKzonAzKzknAjMzErOicDMrOScCMzMSi7PG9NYjcUrh1m4ZAObRkaZ2V1haLDPN4Uxs8I5ETTJ4pXDLFi0ltGduwEYHhllwaK1AE4GZlYodw01ycIlG15MAmNGd+5m4ZINBUVkZpZwImiSTSOjk2o3M2sWJ4ImmdldmVS7mVmzOBE0ydBgH5WuaXu0VbqmMTTYV1BEZmYJDxY3ydiAsGcNmVmrKU0iaIWpm/P7e/3Bb2YtpxSJwFM3zczGV4oxAk/dNDMbXykSgadumpmNrxSJwFM3zczGV4pE4KmbZmbjK8VgsadumpmNrxSJADx108xsPKXoGjIzs/E5EZiZlZwTgZlZyTkRmJmVnBOBmVnJORGYmZWcIqLoGCZF0lbgyQy7zgCezjmcduT3ZXx+b+rz+zK+dnpvjoqInnpPtF0iyErSsogYKDqOVuP3ZXx+b+rz+zK+Tnlv3DVkZlZyTgRmZiXXyYngpqIDaFF+X8bn96Y+vy/j64j3pmPHCMzMLJtOviIwM7MMnAjMzEquoxKBpCMl3SfpUUmPSLq46JhajaRpklZK+krRsbQKSd2S7pT0Q0nrJb2u6JhahaRL0n9L6yR9TtLBRcdUBEmflrRF0rqqtt+StFTSY+nP3ywyxv3RUYkA2AVcGhHHACcCF0o6puCYWs3FwPqig2gx1wBfjYijgdfi9wcASb3ARcBARLwGmAa8pdioCvOvwBk1bZcB34iIVwPfSH9vSx2VCCJic0SsSLe3k/yD9t1oUpJmAX8M3Fx0LK1C0nTgDcAtABHxy4gYKTaqlnIgUJF0IPAbwKaC4ylERNwPPFvTfA5wa7p9KzC/qUFNoY5KBNUkzQH6gQeLjaSl/BPwd8Cvig6khbwS2Ar8S9pldrOklxYdVCuIiGHg48BTwGZgW0R8rdioWsrLI2Jzuv0z4OVFBrM/OjIRSDoE+BLw/oh4vuh4WoGks4AtEbG86FhazIHA8cCnIqIf+DltfIk/ldI+73NIkuVM4KWS3l5sVK0pknn4bTsXv+MSgaQukiRwe0QsKjqeFnIScLakJ4DPA6dI+myxIbWEjcDGiBi7cryTJDEYnAY8HhFbI2InsAh4fcExtZL/lHQEQPpzS8Hx7LOOSgSSRNLXuz4iri46nlYSEQsiYlZEzCEZ8PtmRJT+211E/Az4qaS+tOlU4NECQ2olTwEnSvqN9N/WqXggvdpdwLvS7XcBXy4wlv3SUYmA5FvvO0i+7a5KH2cWHZS1vP8J3C5pDTAP+IeC42kJ6VXSncAKYC3J50VHlFSYLEmfA74P9EnaKOndwEeB0yU9RnL19NEiY9wfLjFhZlZynXZFYGZmk+REYGZWck4EZmYl50RgZlZyTgRmZiXnRGC5k7Q7ncq7TtLdkrpzOs8DU/Q6J0valpac2CDp/nRl9tjzfyXpnQ2OL2zhlaR+Sbek2+dLCkmnVT0/P207L/395rHijJKekDSjwet/vZ0rbdrenAisGUYjYl5awfJZ4MI8ThIRU/nh+52I6I+IPpIKnNdJOjU9zw0RcdsEx55MsStwLweurfp9LXtWDX0rsHrsl4h4T0RMZhHdZ4C/3q8IraU4EVizfZ+0Imz6zfnF+yJIuk7S+en2E5I+JGmFpLWSjk7br0xrw39L0k8kXVR1/AtVr/utqnsM3J6ujEXSmWnbcknXZrkvQ0SsAj4M/E1VDB9Ity9K73+xRtLn02KHfwVckl4F/YGkN0t6ML3C+Lqkl2f4W96ZvuZqSZ9J23okfUnSw+njpNpYJR0KHBcRq6uavwOcIKkrrcP1KmBV1THfkjRQ57XeLumh9O+4UdK09Km7SJKJdYgDiw7AyiP9IDmVtORzBk9HxPGS/hr4APCetP1o4I3AocAGSZ9Ka+FU6weOJSmb/D3gJEnLgBuBN0TE4+lq0axWAEN12i8DXhkROyR1R8SIpBuAFyLi4/Bi8bYTIyIkvYekAuyl4/0twO8Afw+8PiKelvRb6b7XAJ+IiO9Kmg0sAX63Jp4BYF1NWwBfBwaB6SQf5K+c6I+V9LvAnwMnRcROSf8MvA24LSKek3SQpMMj4pmJXsfagxOBNUNF0iqSK4H1wNKMx40VDVwOnFvV/u8RsQPYIWkLSfnfjTXHPhQRGwHSc88BXgB+EhGPp/t8DrggYywap30NSXmKxcDicfaZBXxBSWGylwCPVz1X7285BbgjIp4GiIixOvinAcekFzcAh0k6JCJeqHq9I0jKatf6PEkX13SSJHT5uH9p4lTg94CH0/NV2LOo2haSiqROBB3AXUPWDKMRMQ84iuQDdWyMYBd7/j9YexvEHenP3ez5pWVH1Xbtc5PZZzL6qV9w7Y+B60kqlj6s5AYutT4JXBcRc4G/ZM+/czJxHkByZTEvffTWJAGAUfZ+H4mIh4C5wIyI+NEE5xgj4Naqc/VFxJVVzx+cnss6gBOBNU1E/ILkW+ml6QfmkyTfcA9KZxKdmnMIG4DfTvvxIen6aEjSccD/JvnAr24/ADgyIu4D/hfJt+1DgO0kXT1jpgPD6fa7aOybwJ9JOjw9z1jX0NdICuSNnX9enWPXk4wB1HMZja8ExnwDOE/Sy8ZikHRUui3gFcATGV/LWpy7hqypImKlkiqfb42Iz0j6Ikmf9uPAypzPPZqON3xV0s+BhyfY/Q8krSS5PeMW4KKI+EbNPtOAzyq53aWAa9MxgruBOyWdQ/LBfSVwh6TnSD7kJ+yfj4hHJH0E+Lak3STvy/kkSfT69P07ELifZGC6+tgfSpou6dD0dq3Vz9070Xlr9n1U0t8DX0sT3k6SK7knSbqMfhARu7K+nrU2Vx+1UhnrU0+/1V4PPBYRnyg6rqkk6RJge0Tkcm9qSdcAd9VJjNam3DVkZfPedPD4EZIumxsLjicPn2LPsYepts5JoLP4isDMrOR8RWBmVnJOBGZmJedEYGZWck4EZmYl50RgZlZy/x8hUK+d2gX6WAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Running Distance in Mile\n",
    "x = np.array([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "\n",
    "# Water Drinks in Litre\n",
    "y = np.array([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Running Distance (Mile)')\n",
    "plt.ylabel('Water Drinks (Litre)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to obtain the best line, we should define error first\n",
    "\n",
    "- For linear relationship, mean-square-error (MSE) represents is it a good line (good model) or not \n",
    "\n",
    "- $y[i]$ and $y_{pred}[i]$ are i-th element of list `y` and list `y_pred` respectively where `y_pred[i] = w_1 x[i] +w_0`\n",
    "\n",
    "- Define error as: $E[i] = y_{pred}[i] - y[i]$\n",
    "\n",
    "- Define mean-square-error as: $MSE = \\frac{1}{N} \\sum_{i=0}^{N-1} E[i]^2$\n",
    "\n",
    "- Also mean-square-error is equal to: $MSE = \\frac{1}{N} \\sum_{i=0}^{N-1} (y_{pred}[i] - y[i])^2$ \n",
    "\n",
    "- The parameter $N$ is: $N = len(y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Obtain the MSE for the following two lines:\n",
    "\n",
    "1- `y_pred[i] = 0.7*x[i] + 0.3`\n",
    "\n",
    "2- `y_pred[i] = 0.25163494*x[i] + 0.79880123`\n",
    "\n",
    "Hint: Your function take four input arguments: 1- y, 2- x, 3- slope, 4-intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.518593101764703\n",
      "0.15385767404191164\n"
     ]
    }
   ],
   "source": [
    "def min_sq_error(y, x, w1, w0):\n",
    "    y_pred = (w1*x)+w0\n",
    "    sum_squared_error = sum((y_pred-y)**2)\n",
    "    N = len(y)\n",
    "    mse = sum_squared_error/N\n",
    "    return mse\n",
    "\n",
    "print(min_sq_error(y, x, 0.7, 0.3))\n",
    "print(min_sq_error(y, x, 0.25163494, 0.79880123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Obtain the best line (Coding is not required)\n",
    "\n",
    "- In order the best line, we want to obtain which slope ($w_1$) and intercept ($w_0$) minimize the mean-square-error (MSE)\n",
    "\n",
    "- Mathematically:\n",
    "\n",
    "    - $MSE = \\frac{1}{N} \\sum_{i=0}^{N-1} (y_{pred}[i] - y[i])^2$ \n",
    "\n",
    "    - $MSE = f(w_1, w_0)= \\frac{1}{N} \\sum_{i=0}^{N-1} (w_1x[i] + w_0 - y[i])^2$ \n",
    "\n",
    "The steps in order to obtain the best line: \n",
    "\n",
    "1- Compute: \n",
    "\n",
    "$\\frac{\\partial MSE}{\\partial w_1}$ \n",
    "\n",
    "and\n",
    "\n",
    "$\\frac{\\partial MSE}{\\partial w_0}$\n",
    "\n",
    "2- then obtain $w_1$ and $w_0$ such that:\n",
    "\n",
    "\n",
    "$\\frac{\\partial MSE}{\\partial w_1} = 0$ \n",
    "\n",
    "and\n",
    "\n",
    "$\\frac{\\partial MSE}{\\partial w_0} = 0$\n",
    "\n",
    "- For this part, you need to use partial derivative and you use derivative table\n",
    "\n",
    "- For this part, write down the steps and the solution on a paper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Write a code to return the slope and intercept with given list x and y\n",
    "\n",
    "- After taking partial derivative of mean-squared-error and setting to zero for both $w_1$ and $w_0$ ($\\frac{\\partial MSE}{\\partial w_1} = 0$ $\\frac{\\partial MSE}{\\partial w_0} = 0$)\n",
    "\n",
    "- $w_1$ = is obtained from list x and list y\n",
    "- $w_0 $ = is obtained from $w_1$, list x and list y\n",
    "- Write a Python function that return $w_1$ and $w_0$ from your calculation on the paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.25163494428355315, 0.7988012261753947)\n"
     ]
    }
   ],
   "source": [
    "def slope_intercept_LR(x, y):\n",
    "    w1 = (np.mean(x*y)-(np.mean(x)*np.mean(y)))/(np.mean(x**2)-(np.mean(x))**2)\n",
    "    w0 = np.mean(y)-(np.mean(x)*((np.mean(x*y)-(np.mean(x)*np.mean(y)))/(np.mean(x**2)-(np.mean(x))**2)))\n",
    "    return w1, w0\n",
    "\n",
    "print(slope_intercept_LR(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: After obtain the best line, obtain the variance and mean of error\n",
    "\n",
    "- In Question 3, we have obtained the best line\n",
    "- So, we can error list which its element is: $E[i] = y_{pred}[i] - y[i]$\n",
    "- Write a function that calculate variance and mean of list $E$\n",
    "- Plot the distribution of the error for optimal line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculated mean is:  2.366235294117647\n",
      "The calculated variance is:  0.3471050941241765\n",
      "\n",
      "The given mean is:  2.366235294117647\n",
      "The given variance is:  0.3471050941241765\n"
     ]
    }
   ],
   "source": [
    "def mean_of_LR(x, y):\n",
    "    w1, w0 = slope_intercept_LR(x, y)\n",
    "    y_pred = (w1*x)+w0\n",
    "    return(sum(y_pred)/len(y_pred))\n",
    "\n",
    "def var_of_LR(x,y):\n",
    "    w1, w0 = slope_intercept_LR(x, y)\n",
    "    mean = mean_of_LR(x,y)\n",
    "    y_pred = (w1*x)+w0\n",
    "    variance = np.mean((y_pred-mean)**2)\n",
    "    return variance\n",
    "\n",
    "print('The calculated mean is: ', mean_of_LR(x,y))\n",
    "print('The calculated variance is: ', var_of_LR(x,y))\n",
    "print()\n",
    "\n",
    "w1, w0 = slope_intercept_LR(x, y)\n",
    "y_pred = (w1*x)+w0\n",
    "given_mean = np.mean(y_pred)\n",
    "given_var = np.var(y_pred)\n",
    "print('The given mean is: ', given_mean)\n",
    "print('The given variance is: ', given_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: (Optional but Bonus point) In almost all applications, we update the slope and intercept through iteration\n",
    "\n",
    "- Instead of putting the $\\frac{\\partial MSE}{\\partial w_1} = 0$ $\\frac{\\partial MSE}{\\partial w_0} = 0$\n",
    "    - Initialize the $w_1$ and $w_0$ with arbitrary value, then update them by following Gradient Updating Rule:\n",
    "    - $w_1 = w_1 - step*\\frac{\\partial MSE}{\\partial w_1}$\n",
    "    - $w_0 = w_0 - step*\\frac{\\partial MSE}{\\partial w_0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2518472021724522\n",
      "0.7972964492220543\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w_0 = np.random.randn()\n",
    "w_1 = np.random.randn()\n",
    "step = 0.01\n",
    "epoch = 5000\n",
    "for _ in range(epoch):\n",
    "    w_1 = w_1 - step*(w_1*np.mean([i**2 for i in x]) +w_0*np.mean(x)-np.mean([a*b for a,b in zip(x,y)]))\n",
    "    w_0 = w_0 - step*(w_1*np.mean(x)-np.mean(y)+w_0)\n",
    "print(w_1)\n",
    "print(w_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinregressResult(slope=0.25163494428355404, intercept=0.7988012261753894, rvalue=0.8323917528894436, pvalue=3.391952640710616e-05, stderr=0.0432568020417479)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(stats.linregress(x, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
